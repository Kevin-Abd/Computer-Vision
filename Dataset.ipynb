{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ft61e8Fs8mK"
   },
   "source": [
    "#### Dataset perpration\n",
    "inlcudes cutting, foldering and seperating test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Start: 2020-07-23 13:47:17.555907\n",
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 3839-F69A\n",
      "\n",
      " Directory of C:\\Users\\Worker\\Desktop\\computer-vision\n",
      "\n",
      "2020-07-23  01:28 PM    <DIR>          .\n",
      "2020-07-23  01:28 PM    <DIR>          ..\n",
      "2020-07-23  01:27 PM    <DIR>          .ipynb_checkpoints\n",
      "2020-07-23  01:23 PM    <DIR>          dataset\n",
      "2020-07-23  01:24 PM    <DIR>          model_bkp\n",
      "               0 File(s)              0 bytes\n",
      "               5 Dir(s)  128,900,378,624 bytes free\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import datetime\n",
    "print(f'Start: {datetime.datetime.now()}')\n",
    "%pwd\n",
    "%ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rW8boC-hs8mL",
    "outputId": "25c1013d-2923-4771-fa80-6757e61c1d99",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from cv2 import aruco\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def flatten_photo(dict_arco, width, height, image_path):\n",
    "    \"\"\"flatten phto using aurco dictinary to given size\n",
    "    dict_arco must follow as \n",
    "    {\n",
    "        topleft  : 0\n",
    "        topright : 1\n",
    "        botright : 2\n",
    "        botleft  : 3\n",
    "    }\n",
    "\n",
    "    Args:\n",
    "        dict_arco (dict): arco dictonary\n",
    "        width (int): width of warped picture\n",
    "        height (int): height of warped picture\n",
    "        image_path (string): image to read\n",
    "\n",
    "    Returns:\n",
    "        cv.image: warped image\n",
    "    \"\"\"\n",
    "    try:\n",
    "      I_orginal = cv2.imread(image_path)\n",
    "      # ARUCO finding process\n",
    "      gray = cv2.cvtColor(I_orginal, cv2.COLOR_BGR2GRAY)\n",
    "      aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "      parameters = aruco.DetectorParameters_create()\n",
    "      corners, ids, rejectedImgPoints = aruco.detectMarkers(\n",
    "          gray, aruco_dict, parameters=parameters)\n",
    "      source_points = np.zeros((4, 2), dtype=np.dtype('int32'))\n",
    "      if len(ids) != 4:\n",
    "          print(\"Less than 4 aruco\", imgPath)\n",
    "          return None\n",
    "      for i in range(4):\n",
    "          id = ids[i][0]\n",
    "          corn = dict_arco[id]\n",
    "          x = corners[i][0][corn][0]\n",
    "          y = corners[i][0][corn][1]\n",
    "          point = (x, y)\n",
    "          source_points[corn][0] = x\n",
    "          source_points[corn][1] = y\n",
    "\n",
    "      dest_points = np.array([\n",
    "          (0, 0),\n",
    "          (width, 0),\n",
    "          (width, height),\n",
    "          (0, height), ])\n",
    "\n",
    "      H, mask = cv2.findHomography(source_points, dest_points, cv2.RANSAC, 4.0)\n",
    "      J_warped = cv2.warpPerspective(I_orginal, H, (width, height))\n",
    "    except:\n",
    "      print(f\"ERROR: path:{image_path}\")\n",
    "      return None\n",
    "    return J_warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dict_arco = {\n",
    "    30: 0,\n",
    "    31: 1,\n",
    "    33: 2,\n",
    "    32: 3,\n",
    "}\n",
    "\n",
    "size = 32  # size of each cell (pixel)\n",
    "with_no = 14  # number of cells in row/width\n",
    "height_no = 21  # number of cells in column/height\n",
    "test_ration = 0.05\n",
    "\n",
    "raw_dir = \"dataset/raw/\"\n",
    "processed_dir = \"dataset/processed/\"\n",
    "test_dir = \"dataset/test/\"\n",
    "\n",
    "list_items_1 = [\n",
    "    [\"no_0\", 10, \"۰\"],\n",
    "    [\"no_1\", 10, \"۱\"],\n",
    "    [\"al_al\", 14, \"ا\"],\n",
    "    [\"al_be\", 14, \"ب\"],\n",
    "    [\"al_pe\", 14, \"پ\"],\n",
    "    [\"al_te\", 14, \"ت\"],\n",
    "    [\"al_sn\", 14, \"ث\"],\n",
    "    [\"al_jm\", 14, \"ج\"],\n",
    "    [\"al_ch\", 14, \"چ\"],\n",
    "    [\"al_hh\", 14, \"ح\"],\n",
    "    [\"al_kh\", 14, \"خ\"],\n",
    "    [\"al_dl\", 14, \"د\"],\n",
    "    [\"al_zl\", 14, \"ذ\"],\n",
    "    [\"al_rr\", 14, \"ر\"],\n",
    "    [\"al_zz\", 14, \"ز\"],\n",
    "    [\"al_jz\", 14, \"ژ\"],\n",
    "    [\"al_sn\", 14, \"س\"],\n",
    "    [\"al_shn\", 14, \"ش\"],\n",
    "    [\"al_sd\", 14, \"ص\"],\n",
    "    [\"no_2\", 10, \"۲\"],\n",
    "    [\"no_3\", 10, \"۳\"]]\n",
    "\n",
    "list_items_2 = [\n",
    "    [\"no_4\", 10, \"۴\"],\n",
    "    [\"no_5\", 10, \"۵\"],\n",
    "    [\"al_zd\", 14, \"ض\"],\n",
    "    [\"al_ta\", 14, \"ط\"],\n",
    "    [\"al_za\", 14, \"ظ\"],\n",
    "    [\"al_ay\", 14, \"ع\"],\n",
    "    [\"al_ghy\", 14, \"غ\"],\n",
    "    [\"al_fe\", 14, \"ف\"],\n",
    "    [\"al_gh\", 14, \"ق\"],\n",
    "    [\"al_kf\", 14, \"ک\"],\n",
    "    [\"al_gf\", 14, \"گ\"],\n",
    "    [\"al_lm\", 14, \"ل\"],\n",
    "    [\"al_mm\", 14, \"م\"],\n",
    "    [\"al_nn\", 14, \"ن\"],\n",
    "    [\"al_vv\", 14, \"و\"],\n",
    "    [\"al_he\", 14, \"ه\"],\n",
    "    [\"al_ye\", 14, \"ی\"],\n",
    "    [\"no_6\", 14, \"۶\"],\n",
    "    [\"no_7\", 14, \"۷\"],\n",
    "    [\"no_8\", 10, \"۸\"],\n",
    "    [\"no_9\", 10, \"۹\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuE-bsDMs8mf",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Class 1:25\n",
      "Class 2:22\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fnames_1 = glob.glob(f\"{raw_dir}/*_1*.jpg\")\n",
    "fnames_2 = glob.glob(f\"{raw_dir}/*_2*.jpg\")\n",
    "fnames_1.sort()\n",
    "fnames_2.sort()\n",
    "\n",
    "print(f\"Class 1:{len(fnames_1)}\")\n",
    "print(f\"Class 2:{len(fnames_2)}\")\n",
    "fs = [fnames_1, fnames_2]\n",
    "ls = [list_items_1, list_items_2]\n",
    "# fs = [fnames_1, fnames_2]\n",
    "# ls = [list_items_1, list_items_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxwABYWas8mh",
    "outputId": "9cd11bb4-fd17-4849-996b-4c160231d40f",
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Image Read: 100%|██████████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00,  9.11it/s]\n",
      "Image Slice: 25it [00:00, ?it/s]\n",
      "Image Read: 100%|██████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.61it/s]\n",
      "Image Slice: 22it [00:00, ?it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "read  25 pictures\n",
      "===========END OF FOLDER==============\n",
      "for ۰ got 250 blocks\n",
      "for ۱ got 250 blocks\n",
      "for ا got 350 blocks\n",
      "for ب got 350 blocks\n",
      "for پ got 350 blocks\n",
      "for ت got 350 blocks\n",
      "for ث got 350 blocks\n",
      "for ج got 350 blocks\n",
      "for چ got 350 blocks\n",
      "for ح got 350 blocks\n",
      "for خ got 350 blocks\n",
      "for د got 350 blocks\n",
      "for ذ got 350 blocks\n",
      "for ر got 350 blocks\n",
      "for ز got 350 blocks\n",
      "for ژ got 350 blocks\n",
      "for س got 350 blocks\n",
      "for ش got 350 blocks\n",
      "for ص got 350 blocks\n",
      "for ۲ got 250 blocks\n",
      "for ۳ got 250 blocks\n",
      "read  22 pictures\n",
      "===========END OF FOLDER==============\n",
      "for ۴ got 220 blocks\n",
      "for ۵ got 220 blocks\n",
      "for ض got 308 blocks\n",
      "for ط got 308 blocks\n",
      "for ظ got 308 blocks\n",
      "for ع got 308 blocks\n",
      "for غ got 308 blocks\n",
      "for ف got 308 blocks\n",
      "for ق got 308 blocks\n",
      "for ک got 308 blocks\n",
      "for گ got 308 blocks\n",
      "for ل got 308 blocks\n",
      "for م got 308 blocks\n",
      "for ن got 308 blocks\n",
      "for و got 308 blocks\n",
      "for ه got 308 blocks\n",
      "for ی got 308 blocks\n",
      "for ۶ got 308 blocks\n",
      "for ۷ got 308 blocks\n",
      "for ۸ got 220 blocks\n",
      "for ۹ got 220 blocks\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# class_1 = np.zeros((len(fnames_1)))\n",
    "# class_2 = np.zeros((len(fnames_2)))\n",
    "\n",
    "for fnames, list_items in zip(fs, ls):\n",
    "    class_pic = np.zeros((len(fnames)),dtype=object)\n",
    "    pic_names = np.zeros((len(fnames)),dtype=object)\n",
    "    index = -1\n",
    "    for image_path in tqdm(fnames, desc=\"Image Read\"):\n",
    "        index = index + 1\n",
    "         \n",
    "        f_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
    "        J_warped = flatten_photo(dict_arco, size*with_no, size*height_no, image_path)\n",
    "        class_pic[index] = J_warped\n",
    "        pic_names[index] = f_name\n",
    "        if J_warped is None:\n",
    "            print(f\"Skipped {image_path}\")\n",
    "            continue\n",
    "    print(\"read \",class_pic.size,\"pictures\")\n",
    "    array_items = np.zeros((len(list_items)),dtype=object)\n",
    "    for it in range(len(list_items)):\n",
    "        array_items[it] = []\n",
    "\n",
    "    for pic, name in tqdm(zip(class_pic,pic_names),desc=\"Image Slice\"):\n",
    "        for row in range(len(list_items)):\n",
    "            tmp = list_items[row][1]\n",
    "            y0 = int(row * size)\n",
    "            y1 = int(y0 + size)\n",
    "            y0 = y0+2\n",
    "            y1 = y1-2\n",
    "            for col in range(tmp):\n",
    "                offs =  int(7 - tmp/2)\n",
    "                x0 = int((offs + col) * size) \n",
    "                x1 = int(x0 + size)\n",
    "                x0 = x0+2\n",
    "                x1 = x1-2\n",
    "                block = pic[y0:y1, x0:x1]\n",
    "                array_items[row].append((block,name))\n",
    "    print(\"===========END OF FOLDER==============\")\n",
    "    for item in range(len(list_items)):\n",
    "        # print(f\"Processing {list_items[item][2]}\")\n",
    "        print(f\"for {list_items[item][2]} got {len(array_items[item])} blocks\" )\n",
    "        train_input, valid_input = train_test_split(array_items[item],\n",
    "                                                    test_size=test_ration, random_state=103)\n",
    "        #Save train data\n",
    "        save_dir = f\"{processed_dir}{list_items[item][0]}__/\"\n",
    "        ensure_dir(save_dir)\n",
    "        for i in range(len(train_input)):\n",
    "            cv2.imwrite(f\"{save_dir}{train_input[i][1]}_{i}.jpg\", train_input[i][0]);\n",
    "        \n",
    "        #Save test data\n",
    "        save_dir = f\"{test_dir}{list_items[item][0]}__/\"\n",
    "        ensure_dir(save_dir)\n",
    "        for i in range(len(valid_input)):\n",
    "            cv2.imwrite(f\"{save_dir}{valid_input[i][1]}_{i}.jpg\", valid_input[i][0]);    \n",
    "            \n",
    "        \n",
    "        # for row in tqdm(len(list_items), desc=\"item\"):\n",
    "        #     tmp = list_items[row][1]\n",
    "        # \n",
    "        #     y0 = int(row * size)\n",
    "        #     y1 = int(y0 + size)\n",
    "        # \n",
    "        #     y0 = y0+2\n",
    "        #     y1 = y1-2\n",
    "        #     for col in range(tmp):\n",
    "        #         offs =  int(7 - tmp/2)\n",
    "        # \n",
    "        #         x0 = int((offs + col) * size) \n",
    "        #         x1 = int(x0 + size)\n",
    "        #         x0 = x0+2\n",
    "        #         x1 = x1-2\n",
    "        # \n",
    "        #         tmp_arr = J_warped[y0:y1, x0:x1]\n",
    "        #         save_dir = f\"{processed_dir}{list_items[row][0]}__/\"\n",
    "        #         ensure_dir(save_dir)\n",
    "        #         cv2.imwrite(f\"{save_dir}{f_name}_{col}.jpg\", tmp_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(28, 28, 3)\n",
      "2\n",
      "2\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x27f083f9648>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 65
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print((train_input[0][0].shape))\n",
    "print(len(train_input[0]))\n",
    "print(len(valid_input[0]))\n",
    "\n",
    "# plt.imshow(train_input[0][0])\n",
    "plt.imshow(valid_input[0][0])\n",
    "\n",
    "# plt.imshow(array_items[2][60])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Keras_Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}