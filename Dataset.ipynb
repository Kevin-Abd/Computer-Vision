{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ft61e8Fs8mK"
   },
   "source": [
    "#### Dataset perpration\n",
    "inlcudes cutting, foldering and seperating test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Start: 2020-07-23 13:35:05.971437\n",
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 3839-F69A\n",
      "\n",
      " Directory of C:\\Users\\Worker\\Desktop\\computer-vision\n",
      "\n",
      "2020-07-23  01:28 PM    <DIR>          .\n",
      "2020-07-23  01:28 PM    <DIR>          ..\n",
      "2020-07-23  01:27 PM    <DIR>          .ipynb_checkpoints\n",
      "2020-07-23  01:23 PM    <DIR>          dataset\n",
      "2020-07-23  01:24 PM    <DIR>          model_bkp\n",
      "               0 File(s)              0 bytes\n",
      "               5 Dir(s)  129,291,948,032 bytes free\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import datetime\n",
    "print(f'Start: {datetime.datetime.now()}')\n",
    "%pwd\n",
    "%ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rW8boC-hs8mL",
    "outputId": "25c1013d-2923-4771-fa80-6757e61c1d99",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from cv2 import aruco\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def flatten_photo(dict_arco, width, height, image_path):\n",
    "    \"\"\"flatten phto using aurco dictinary to given size\n",
    "    dict_arco must follow as \n",
    "    {\n",
    "        topleft  : 0\n",
    "        topright : 1\n",
    "        botright : 2\n",
    "        botleft  : 3\n",
    "    }\n",
    "\n",
    "    Args:\n",
    "        dict_arco (dict): arco dictonary\n",
    "        width (int): width of warped picture\n",
    "        height (int): height of warped picture\n",
    "        image_path (string): image to read\n",
    "\n",
    "    Returns:\n",
    "        cv.image: warped image\n",
    "    \"\"\"\n",
    "    try:\n",
    "      I_orginal = cv2.imread(image_path)\n",
    "      # ARUCO finding process\n",
    "      gray = cv2.cvtColor(I_orginal, cv2.COLOR_BGR2GRAY)\n",
    "      aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "      parameters = aruco.DetectorParameters_create()\n",
    "      corners, ids, rejectedImgPoints = aruco.detectMarkers(\n",
    "          gray, aruco_dict, parameters=parameters)\n",
    "      source_points = np.zeros((4, 2), dtype=np.dtype('int32'))\n",
    "      if len(ids) != 4:\n",
    "          print(\"Less than 4 aruco\", imgPath)\n",
    "          return None\n",
    "      for i in range(4):\n",
    "          id = ids[i][0]\n",
    "          corn = dict_arco[id]\n",
    "          x = corners[i][0][corn][0]\n",
    "          y = corners[i][0][corn][1]\n",
    "          point = (x, y)\n",
    "          source_points[corn][0] = x\n",
    "          source_points[corn][1] = y\n",
    "\n",
    "      dest_points = np.array([\n",
    "          (0, 0),\n",
    "          (width, 0),\n",
    "          (width, height),\n",
    "          (0, height), ])\n",
    "\n",
    "      H, mask = cv2.findHomography(source_points, dest_points, cv2.RANSAC, 4.0)\n",
    "      J_warped = cv2.warpPerspective(I_orginal, H, (width, height))\n",
    "    except:\n",
    "      print(f\"ERROR: path:{image_path}\")\n",
    "      return None\n",
    "    return J_warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "('11', 'ب')\n",
      "False\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "dict_arco = {\n",
    "    30: 0,\n",
    "    31: 1,\n",
    "    33: 2,\n",
    "    32: 3,\n",
    "}\n",
    "\n",
    "size = 32  # size of each cell (pixel)\n",
    "with_no = 14  # number of cells in row/width\n",
    "height_no = 21  # number of cells in column/height\n",
    "test_ration = 0.05\n",
    "\n",
    "raw_dir = \"dataset/raw/\"\n",
    "processed_dir = \"dataset/processed/\"\n",
    "test_dir = \"dataset/test/\"\n",
    "\n",
    "list_items_1 = [\n",
    "    [\"no_0\", 10, \"۰\"],\n",
    "    [\"no_1\", 10, \"۱\"],\n",
    "    [\"al_al\", 14, \"ا\"],\n",
    "    [\"al_be\", 14, \"ب\"],\n",
    "    [\"al_pe\", 14, \"پ\"],\n",
    "    [\"al_te\", 14, \"ت\"],\n",
    "    [\"al_sn\", 14, \"ث\"],\n",
    "    [\"al_jm\", 14, \"ج\"],\n",
    "    [\"al_ch\", 14, \"چ\"],\n",
    "    [\"al_hh\", 14, \"ح\"],\n",
    "    [\"al_kh\", 14, \"خ\"],\n",
    "    [\"al_dl\", 14, \"د\"],\n",
    "    [\"al_zl\", 14, \"ذ\"],\n",
    "    [\"al_rr\", 14, \"ر\"],\n",
    "    [\"al_zz\", 14, \"ز\"],\n",
    "    [\"al_jz\", 14, \"ژ\"],\n",
    "    [\"al_sn\", 14, \"س\"],\n",
    "    [\"al_shn\", 14, \"ش\"],\n",
    "    [\"al_sd\", 14, \"ص\"],\n",
    "    [\"no_2\", 10, \"۲\"],\n",
    "    [\"no_3\", 10, \"۳\"]]\n",
    "\n",
    "list_items_2 = [\n",
    "    [\"no_4\", 10, \"۴\"],\n",
    "    [\"no_5\", 10, \"۵\"],\n",
    "    [\"al_zd\", 14, \"ض\"],\n",
    "    [\"al_ta\", 14, \"ط\"],\n",
    "    [\"al_za\", 14, \"ظ\"],\n",
    "    [\"al_ay\", 14, \"ع\"],\n",
    "    [\"al_ghy\", 14, \"غ\"],\n",
    "    [\"al_fe\", 14, \"ف\"],\n",
    "    [\"al_gh\", 14, \"ق\"],\n",
    "    [\"al_kf\", 14, \"ک\"],\n",
    "    [\"al_gf\", 14, \"گ\"],\n",
    "    [\"al_lm\", 14, \"ل\"],\n",
    "    [\"al_mm\", 14, \"م\"],\n",
    "    [\"al_nn\", 14, \"ن\"],\n",
    "    [\"al_vv\", 14, \"و\"],\n",
    "    [\"al_he\", 14, \"ه\"],\n",
    "    [\"al_ye\", 14, \"ی\"],\n",
    "    [\"no_6\", 14, \"۶\"],\n",
    "    [\"no_7\", 14, \"۷\"],\n",
    "    [\"no_8\", 10, \"۸\"],\n",
    "    [\"no_9\", 10, \"۹\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuE-bsDMs8mf",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10 30 32\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fnames_1 = glob.glob(f\"{raw_dir}*_1*.jpg\")\n",
    "fnames_2 = glob.glob(f\"{raw_dir}/*_2*.jpg\")\n",
    "print(f\"Class 1:{len(fnames_1)}\")\n",
    "print(f\"Class 2:{len(fnames_2)}\")\n",
    "fs = [fnames_1, fnames_2]\n",
    "ls = [list_items_1, list_items_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxwABYWas8mh",
    "outputId": "9cd11bb4-fd17-4849-996b-4c160231d40f",
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 1212.89it/s]\n",
      " 10%|█         | 1/10 [00:00<00:00,  9.44it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 1559.46it/s]\n",
      "\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 120/120 [00:00<00:00, 1009.03it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  9.39it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 1579.99it/s]\n",
      "\n",
      "100%|██████████| 120/120 [00:00<00:00, 1519.96it/s]\n",
      " 50%|█████     | 5/10 [00:00<00:00, 10.04it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 1559.38it/s]\n",
      "\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 168/168 [00:00<00:00, 1571.08it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00, 10.06it/s]\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 168/168 [00:00<00:00, 1389.28it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00,  9.24it/s]\n",
      "100%|██████████| 120/120 [00:00<00:00, 1539.43it/s]\n",
      "\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 120/120 [00:00<00:00, 923.65it/s] \u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.64it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "train ['dataset/processed\\\\no_0__', 'dataset/processed\\\\no_1__', 'dataset/processed\\\\no_2__', 'dataset/processed\\\\no_3__', 'dataset/processed\\\\no_4__', 'dataset/processed\\\\no_5__', 'dataset/processed\\\\no_6__', 'dataset/processed\\\\no_7__', 'dataset/processed\\\\no_8__', 'dataset/processed\\\\no_9__']\n",
      "train dataset/processed\\no_0__\n",
      "train dataset/processed\\no_1__\n",
      "train dataset/processed\\no_2__\n",
      "train dataset/processed\\no_3__\n",
      "train dataset/processed\\no_4__\n",
      "train dataset/processed\\no_5__\n",
      "train dataset/processed\\no_6__\n",
      "train dataset/processed\\no_7__\n",
      "train dataset/processed\\no_8__\n",
      "train dataset/processed\\no_9__\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for fnames, list_items in zip(fs, ls):\n",
    "    for image_path in tqdm(fnames, desc=\"Image\"):\n",
    "        print(f\"Image {image_path}\")\n",
    "        f_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
    "        J_warped = flatten_photo(dict_arco, size*with_no, size*height_no, image_path)\n",
    "        if J_warped is None:\n",
    "            print(f\"Skipped {image_path}\")\n",
    "            continue\n",
    "        for row in tqdm(len(list_items), desc=\"item\"):\n",
    "            tmp = list_items[row][1]\n",
    "            \n",
    "            y0 = int(row * size)\n",
    "            y1 = int(y0 + size)\n",
    "            \n",
    "            y0 = y0+2\n",
    "            y1 = y1-2\n",
    "            for col in range(tmp):\n",
    "                offs =  int(7 - tmp/2)\n",
    "                \n",
    "                x0 = int((offs + col) * size) \n",
    "                x1 = int(x0 + size)\n",
    "                x0 = x0+2\n",
    "                x1 = x1-2\n",
    "                \n",
    "                tmp_arr = J_warped[y0:y1, x0:x1]\n",
    "                save_dir = f\"{processed_dir}{list_items[row][0]}__/\"\n",
    "                ensure_dir(save_dir)\n",
    "                cv2.imwrite(f\"{save_dir}{f_name}_{col}.jpg\", tmp_arr)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Keras_Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}